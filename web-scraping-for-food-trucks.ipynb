{
 "metadata": {
  "name": "",
  "signature": "sha256:70ccc08fb1db9616529b600ad83df3d6da48ce3a3e858d682398bcd41b5bda14"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Web Scraping\n",
      "It is just a way of getting data from web.\n",
      "\n",
      "There are following ways how we can collect data:\n",
      "* Direct Download\n",
      "* Using API\n",
      "* Gathering from web pages\n",
      "\n",
      "The third one above is web scraping. It simply means to writing the scripts(may be python scripts) to grab the data from web pages. It is more fun than direct download.\n",
      "\n",
      "Many different Python libraries are available for web Scraping. I used *[pattern](https://pypi.python.org/pypi/Pattern)* and [requests](http://docs.python-requests.org/en/latest/) here. BeautifilSoup, [Scrapy](http://scrapy.org/) are other libraries for same purpose."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Web Scraping for finding list of all food trucks and their details"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# requests is for downloading data(text) from the web.\n",
      "import requests\n",
      "\n",
      "# pattern and beautifulsoup are for navigating through DOM\n",
      "from pattern import web\n",
      "\n",
      "# function 3\n",
      "def get_food_truck_link(url):\n",
      "    '''for a given food truck link inside the main_url find the real\n",
      "    link of food truck and return'''\n",
      "    \n",
      "def get_city_url(url):\n",
      "\t'''To fetch and return the dictonary of all cities and \n",
      "\ttheir id present on main page.\n",
      "    Step 1'''\n",
      "    # making get request to the given url\n",
      "\tr = requests.get(url)\n",
      "\thtml = r.text\n",
      "\t'''Since sub-footer of the main page contain list of all countries and their link, \n",
      "    parsing is being done only on sub-footer of main page.'''\n",
      "\tsubfooter_index = html.find('id=\"subfooter\"')\n",
      "\tfooter = html[subfooter_index : html[subfooter_index:].find('</ul></div>')+subfooter_index]\n",
      "\tdom = web.Element(footer)\n",
      "\tcity_link = {}\n",
      "\tfor li in dom.by_tag('li'):\n",
      "\t\tcity = li.by_tag('a')[0].content\n",
      "\t\tinner_link = li.by_tag('a')[0].attributes.get('href', '')\n",
      "\t\tcity_link[city] = inner_link\n",
      "\treturn city_link\n",
      "\t\n",
      "# function 2\n",
      "def get_food_trucks(url):\n",
      "\t'''For a given city url find all food trucks present on the \n",
      "\tpage of that city'''\n",
      "\t\n",
      "    \n",
      "main_url = 'http://roaminghunger.com/'  \n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    # step 1 is to get a dict of all cities and their link address in roaminhunger.com\n",
      "\tcity_link = get_city_url(main_url)\n",
      "\tprint city_link"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{u'Nashville': u'/bna', u'Chicago': u'/chi', u'Philadelphia': u'/phl', u'Denver': u'/den', u'Other': u'/oth', u'Vancouver': u'/yvr', u'Washington DC': u'/dc', u'San Francisco': u'/sf', u'New Orleans': u'/nol', u'Columbus': u'/cmh', u'Indianapolis': u'/ind', u'Phoenix': u'/phx', u'Sacramento': u'/sac', u'Dallas': u'/dfw', u'Durham': u'/rdu', u'Los Angeles': u'/la', u'Orange County': u'/oc', u'Atlanta': u'/atl', u'San Antonio': u'/sat', u'Tampa': u'/tpa', u'Honolulu': u'/hnl', u'Miami': u'/mia', u'San Jose': u'/sjc', u'Orlando': u'/orl', u'Kansas City': u'/ksc', u'Detroit': u'/det', u'San Diego': u'/sd', u'New York': u'/ny', u'Austin': u'/aus', u'St. Louis': u'/stl', u'Houston': u'/hou', u'Boston': u'/bos', u'Minneapolis': u'/msp', u'Las Vegas': u'/lv', u'Cleveland': u'/cle', u'Portland': u'/pdx', u'Seattle': u'/sea'}\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}